{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EIS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 字段映射关系\n",
    "column_mapping = {\n",
    "    \"Data_Point\": \"Data Point\",\n",
    "    \"Test_Time(s)\": \"Test Time (s)\",\n",
    "    \"Date_Time\": \"Date Time\",\n",
    "    \"Step_Time(s)\": \"Step Time (s)\",\n",
    "    \"Step_Index\": \"Step Index\",\n",
    "    \"Cycle_Index\": \"Cycle Index\",\n",
    "    \"Current(A)\": \"Current (A)\",\n",
    "    \"Voltage(V)\": \"Voltage (V)\",\n",
    "    \"Charge_Capacity(Ah)\": \"Charge Capacity (Ah)\",\n",
    "    \"Discharge_Capacity(Ah)\": \"Discharge Capacity (Ah)\",\n",
    "    \"Charge_Energy(Wh)\": \"Charge Energy (Wh)\",\n",
    "    \"Discharge_Energy(Wh)\": \"Discharge Energy (Wh)\",\n",
    "    \"dV/dt(V/s)\": \"dV/dt (V/s)\",\n",
    "    \"Internal_Resistance(Ohm)\": \"Internal Resistance (Ohm)\",\n",
    "    \"Is_FC_Data\": \"Is FC Data\",\n",
    "    \"AC_Impedance(Ohm)\": \"AC Impedance (Ohm)\",\n",
    "    \"ACI_Phase_Angle(Deg)\": \"ACI Phase Angle (Deg)\",\n",
    "    \"Temperature (C)_1\": \"Temperature (C)_1\",\n",
    "    \"Temperature (C)_2\": \"Temperature (C)_2\",\n",
    "    \"Time_sec\": \"Time_sec\",\n",
    "    \"Current_Amp\": \"Current_Amp\",\n",
    "    \"Voltage_Volt\": \"Voltage_Volt\",\n",
    "    \"Charge_Ah\": \"Charge_Ah\",\n",
    "    \"Discharge_Ah\": \"Discharge_Ah\",\n",
    "    \"Frequency (Hz)\": \"Frequency (Hz)\",\n",
    "    \"Z' (Ω)\": \"Z' (Ohm)\",\n",
    "    \"-Z'' (Ω)\": \"-Z'' (Ohm)\",\n",
    "    \"Z (Ω)\": \"Z (Ohm)\",\n",
    "    \"-Phase (°)\": \"-Phase (Deg)\",\n",
    "    \"Freq(Hz)\": \"Freq (Hz)\",\n",
    "    \"Ampl\": \"Ampl\",\n",
    "    \"Bias\": \"Bias\",\n",
    "    \"Time(Sec)\": \"Time (Sec)\",\n",
    "    \"Z'(a)\": \"Z'(a)\",\n",
    "    \"Z''(b)\": \"Z''(b)\",\n",
    "    \"GD\": \"GD\",\n",
    "    \"Err\": \"Err\",\n",
    "    \"Range\": \"Range\",\n",
    "    \"SOC\": \"SOC\",\n",
    "    \"Real Part of Impedance\": \"Real Part of Impedance\",\n",
    "    \"Imaginary Part of Impedance\": \"Imaginary Part of Impedance\",\n",
    "    \"Cell Temperature\": \"Cell Temperature\",\n",
    "    \"Temperature at Cell Connector\": \"Temperature at Cell Connector\"\n",
    "}\n",
    "\n",
    "all_cols = list(column_mapping.values())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from keras.utils import  to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense,Input\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc,f1_score\n",
    "from utils import calculate_metrics\n",
    "from keras.optimizers import Adam\n",
    "from KAN import KANLinear\n",
    "from TransformerEncoer import Encoder\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']   #显示中文\n",
    "plt.rcParams['axes.unicode_minus']=False       #显示负号\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "battery_material_dict = {\n",
    "    0: 'NCR18650B',\n",
    "    1: 'unknown',\n",
    "    2: 'Eunicell LR2032',\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "LOOKBACK = 30"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def split_sequence(sequence, look_back,pre_l):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_element_index = i + look_back\n",
    "        if end_element_index > len(sequence) - 1 -pre_l:\n",
    "            break\n",
    "        sequence_x, sequence_y = sequence[i:end_element_index], sequence[end_element_index:end_element_index+pre_l]\n",
    "        X.append(sequence_x)\n",
    "        y.append(sequence_y)\n",
    "\n",
    "    return np.array(X).astype('float32'),np.array(y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SANDIA_X = []\n",
    "SANDIA_Y = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "def SANDIA_PARSE(SANDIA_LCO_files,tearget=1):\n",
    "    for fn in SANDIA_LCO_files:\n",
    "        empty_df = pd.DataFrame(columns=all_cols)\n",
    "        try:\n",
    "            with open(fn,'r') as f:\n",
    "                if '_Pristine_' in fn:\n",
    "                    eis_data = f.readlines()[1:]\n",
    "                else:\n",
    "                    eis_data = f.readlines()[123:]\n",
    "            with open('temp','w') as f:\n",
    "                f.writelines(eis_data)\n",
    "            if '_Pristine_' in fn:\n",
    "                eis_data_df = pd.read_csv('temp',header=None,names=['index','Frequency (Hz)',\"Z' (Ω)\",\"-Z'' (Ω)\",'Z (Ω)','-Phase (°)','Time (s)'])\n",
    "                empty_df['Frequency (Hz)'] = eis_data_df['Frequency (Hz)'].values\n",
    "                empty_df['Z\\' (Ohm)'] = eis_data_df['Z\\' (Ω)'].values\n",
    "                empty_df['-Z\\'\\' (Ohm)'] = eis_data_df['-Z\\'\\' (Ω)'].values\n",
    "                empty_df['-Phase (Deg)'] = eis_data_df['-Phase (°)'].values\n",
    "                empty_df = empty_df.fillna(0)\n",
    "                eis_data = empty_df.values\n",
    "            else:\n",
    "                eis_data_df = pd.read_csv('temp',header=None,names=['Freq(Hz)','Ampl',\"Bias\",\"Time(Sec)\",\"Z'(a)\",\"Z''(b)\",'GD','Err','Range'])\n",
    "                empty_df['Frequency (Hz)'] = eis_data_df['Freq(Hz)'].values\n",
    "                empty_df['Z\\' (Ohm)'] = eis_data_df[\"Z'(a)\"].values\n",
    "                empty_df['-Z\\'\\' (Ohm)'] = eis_data_df[\"Z''(b)\"].values\n",
    "                empty_df = empty_df.fillna(0)\n",
    "                eis_data = empty_df.values\n",
    "            xx,_ = split_sequence(scaler.fit_transform(eis_data),LOOKBACK,1)\n",
    "            SANDIA_X.append(xx)\n",
    "            SANDIA_Y.append(np.full(len(xx),tearget))\n",
    "        except: continue"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "SANDIA_LCO_files = ['./data/Sandia/EIS_Data/'+ i for i in os.listdir('./data/Sandia/EIS_Data') if i.startswith('LCO')]\n",
    "SANDIA_PARSE(SANDIA_LCO_files,0)\n",
    "SANDIA_LCO_files = ['./data/Sandia/EIS_Data/'+ i for i in os.listdir('./data/Sandia/EIS_Data') if i.startswith('LFP')]\n",
    "SANDIA_PARSE(SANDIA_LCO_files,0)\n",
    "SANDIA_LCO_files = ['./data/Sandia/EIS_Data/'+ i for i in os.listdir('./data/Sandia/EIS_Data') if i.startswith('NMC')]\n",
    "SANDIA_PARSE(SANDIA_LCO_files,0)\n",
    "SANDIA_LCO_files = ['./data/Sandia/EIS_Data/'+ i for i in os.listdir('./data/Sandia/EIS_Data') if i.startswith('NCA')]\n",
    "SANDIA_PARSE(SANDIA_LCO_files,0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ZHANG = pd.read_csv('./data/Zhang/EIS data/EIS data/EIS_state_IX_25C08.txt',sep='\\t')\n",
    "empty_df = pd.DataFrame(columns=all_cols)\n",
    "empty_df['Frequency (Hz)'] = ZHANG['freq/Hz'].values\n",
    "empty_df[\"Z\\'\\'(b)\"] = ZHANG['           Re(Z)/Ohm'].values\n",
    "empty_df[\"Z\\' (Ohm)\"] = ZHANG['  -Im(Z)/Ohm'].values\n",
    "empty_df[\"Z (Ohm)\"] = ZHANG['   |Z|/Ohm'].values\n",
    "empty_df[\"-Phase (Deg)\"] = ZHANG['   Phase(Z)/deg'].values\n",
    "ZHANG =empty_df.iloc[1000:2000,:]\n",
    "ZHANG = ZHANG.fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SCIWELL_files = ['./data/SCIWELL/cell_checkup/cell_checkups/EIS/' + i for i in os.listdir('./data/SCIWELL/cell_checkup/cell_checkups/EIS') if i.endswith('.csv')]\n",
    "SCIWELL = pd.read_csv(SCIWELL_files[0]).loc[:,['Frequency [Hz]','Real Part of Impedance [Ohm]','Imaginary Part of Impedance [Ohm]']]\n",
    "empty_df = pd.DataFrame(columns=all_cols)\n",
    "empty_df['Frequency (Hz)'] = SCIWELL['Frequency [Hz]'].values\n",
    "empty_df['Real Part of Impedance'] = SCIWELL['Real Part of Impedance [Ohm]'].values\n",
    "empty_df['Imaginary Part of Impedance'] = SCIWELL['Imaginary Part of Impedance [Ohm]'].values\n",
    "SCIWELL = empty_df.fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "all_X = []\n",
    "all_Y = []\n",
    "\n",
    "SCIWELL_v = SCIWELL.values\n",
    "xx,_ = split_sequence(SCIWELL_v/(np.max(SCIWELL_v,axis=0)),30,pre_l=1)\n",
    "all_X.append(xx)\n",
    "all_Y.append(np.full((xx.shape[0],1),1))\n",
    "\n",
    "ZHANG_v = ZHANG.values\n",
    "xx,_ = split_sequence(ZHANG_v/np.max(ZHANG_v,axis=0),LOOKBACK,pre_l=1)\n",
    "all_X.append(xx)\n",
    "all_Y.append(np.full((xx.shape[0],1),2))\n",
    "\n",
    "\n",
    "all_X = np.concatenate(all_X,axis=0)\n",
    "all_Y = np.concatenate(all_Y,axis=0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SANDIA_X = np.concatenate(SANDIA_X, axis=0)\n",
    "SANDIA_Y = np.array(SANDIA_Y)\n",
    "SANDIA_Y = np.concatenate(SANDIA_Y,axis=0)\n",
    "all_X = np.concatenate([all_X, SANDIA_X])\n",
    "all_Y = np.concatenate([all_Y, np.expand_dims(SANDIA_Y, axis=1)])\n",
    "all_Y = to_categorical(all_Y,3)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "class AdpWeightedLoss():\n",
    "    def __init__(self):\n",
    "        self.class_weights = tf.Variable(tf.ones(shape=(4,)), trainable=True)\n",
    "\n",
    "    def weighted_categorical_crossentropy(self,y_true, y_pred):\n",
    "        cross_entropy = categorical_crossentropy(y_true, y_pred)\n",
    "        y_true_idx = tf.argmax(y_true, axis=-1)\n",
    "        weights = tf.gather(self.class_weights, y_true_idx)\n",
    "        positive_weights = tf.nn.softplus(weights)\n",
    "        weighted_loss = cross_entropy * positive_weights\n",
    "        return weighted_loss\n",
    "    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.weighted_categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "def get_model():\n",
    "    inp = Input((30,43))\n",
    "    temp = Dense(80, activation='relu')(inp)\n",
    "    ts_encoder = Encoder(d_model=80,num_heads=4,seql=30,dropout_rate=0,N_block=1,name='encoder')\n",
    "    encoder_outputs = ts_encoder(temp) # x,lstm_pe_embeding,mha_results_list,attn_results_list\n",
    "    temp = encoder_outputs[0]  # 只取第一个输出 \n",
    "    temp = Flatten()(temp)\n",
    "    kan = KANLinear(128)\n",
    "    temp = kan(temp)\n",
    "    temp = KANLinear(80)(temp)\n",
    "    temp = Dense(64,activation='relu')(temp)\n",
    "    out = Dense(3,activation='softmax')(temp)\n",
    "    model = Model(inp, out)\n",
    "    return model,kan\n",
    "\n",
    "\n",
    "\n",
    "class F1Callback(Callback):\n",
    "    def __init__(self, validation_data=(), patience=20, fold=0):\n",
    "        super(F1Callback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.best_f1 = 0\n",
    "        self.wait = 0\n",
    "        self.filepath = f'./weights/EIS_Trans_KAN_models_fold_{fold}.weights.h5'\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # 预测验证集\n",
    "        y_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        y_val = np.argmax(self.y_val, axis=1)\n",
    "        \n",
    "        # 计算F1分数\n",
    "        current_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "        print(f'\\nValidation F1 Score: {current_f1:.4f}')\n",
    "        \n",
    "        # 如果当前F1分数比之前的好，则保存模型\n",
    "        if current_f1 > self.best_f1:\n",
    "            print(f'\\nF1 improved from {self.best_f1:.4f} to {current_f1:.4f}, saving model to {self.filepath}')\n",
    "            self.best_f1 = current_f1\n",
    "            self.wait = 0\n",
    "            self.model.save_weights(self.filepath)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f'\\nEarly stopping: F1 has not improved for {self.patience} epochs.')\n",
    "                self.model.stop_training = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from his_plot import plot_training_history\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_preds = []\n",
    "all_reals = []\n",
    "all_y_scores = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(all_X), 1):\n",
    "    print(f'************************** Fold {fold} ***************************')\n",
    "    \n",
    "    x_train, x_test = all_X[train_index], all_X[test_index]\n",
    "    y_train, y_test = all_Y[train_index], all_Y[test_index]\n",
    "    \n",
    "    # 处理 NaN\n",
    "    X_train = np.nan_to_num(x_train, nan=0)\n",
    "    X_test = np.nan_to_num(x_test, nan=0)\n",
    "    y_train = np.nan_to_num(y_train, nan=0)\n",
    "    y_test = np.nan_to_num(y_test, nan=0)\n",
    "\n",
    "    # 获取模型\n",
    "    model, kan = get_model()\n",
    "    adploss = AdpWeightedLoss()\n",
    "\n",
    "    # 创建回调，传入当前 fold 信息\n",
    "    f1_callback = F1Callback(validation_data=(X_test, y_test), patience=100, fold=fold)\n",
    "    f1_callback.k_flod_number = fold\n",
    "\n",
    "    # 用于保存当前 fold 的所有训练历史\n",
    "    all_histories = []\n",
    "\n",
    "    # ------------------ STEP 1 ------------------\n",
    "    print('STEP 1')\n",
    "    f1_callback.wait = 0\n",
    "    model.compile(loss=adploss, optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    history1 = model.fit(X_train, y_train,\n",
    "                         epochs=20,\n",
    "                         batch_size=64,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         callbacks=[f1_callback],\n",
    "                         verbose=1)\n",
    "    all_histories.append(history1)\n",
    "\n",
    "    # ------------------ STEP 2 ------------------\n",
    "    print('STEP 2')\n",
    "    f1_callback.wait = 0\n",
    "    model.compile(loss=adploss, optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "    history2 = model.fit(X_train, y_train,\n",
    "                         epochs=20,\n",
    "                         batch_size=64,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         callbacks=[f1_callback],\n",
    "                         verbose=1)\n",
    "    all_histories.append(history2)\n",
    "\n",
    "    # ------------------ STEP 3 ------------------\n",
    "    print('STEP 3')\n",
    "    f1_callback.wait = 0\n",
    "    model.compile(loss=adploss, optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "    history3 = model.fit(X_train, y_train,\n",
    "                         epochs=60,\n",
    "                         batch_size=64,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         callbacks=[f1_callback],\n",
    "                         verbose=1)\n",
    "    all_histories.append(history3)\n",
    "\n",
    "    # 合并所有history对象\n",
    "    def merge_histories(histories):\n",
    "        merged_history = {}\n",
    "        for key in histories[0].history.keys():\n",
    "            merged_history[key] = []\n",
    "            for history in histories:\n",
    "                merged_history[key].extend(history.history[key])\n",
    "        return merged_history\n",
    "\n",
    "    # 创建合并后的history对象\n",
    "    merged_history = merge_histories(all_histories)\n",
    "    plot_training_history(merged_history)\n",
    "    model.load_weights(f1_callback.filepath)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_scores = y_pred.copy()\n",
    "    all_y_scores.append(y_scores)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    all_preds.append(y_pred_classes)\n",
    "    all_reals.append(y_test_classes)\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels = [battery_material_dict[i] for i in battery_material_dict.keys()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_scores = np.concatenate(all_y_scores)\n",
    "all_preds_array = np.concatenate(all_preds)\n",
    "all_reals_array = np.concatenate(all_reals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "# 设置美观的样式和配色\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "colors = cycle(['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "                '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "# 计算宏平均和微平均ROC曲线和AUC\n",
    "n_classes = len(labels)\n",
    "\n",
    "# 将真实标签二值化（如果尚未二值化）\n",
    "if all_reals_array.ndim == 1:\n",
    "    all_reals_bin = label_binarize(all_reals_array, classes=range(n_classes))\n",
    "else:\n",
    "    all_reals_bin = all_reals_array\n",
    "\n",
    "# 计算每个类别的ROC曲线和AUC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_reals_bin[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# 计算宏平均ROC曲线和AUC\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# 计算微平均ROC曲线和AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_reals_bin.ravel(), y_scores.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# 创建宏平均ROC曲线图\n",
    "plt.figure(figsize=(12, 9))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 绘制宏平均ROC曲线\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label=f'Macro-average ROC curve (AUC = {roc_auc[\"macro\"]:.4f})',\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# 绘制每个类别的ROC曲线\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of class {labels[i]} (AUC = {roc_auc[i]:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Macro-average ROC Curve', fontsize=14)\n",
    "\n",
    "# 创建悬浮表格\n",
    "table_data = [['Class', 'AUC']]\n",
    "for i in range(n_classes):\n",
    "    table_data.append([labels[i], f'{roc_auc[i]:.4f}'])\n",
    "table_data.append(['Macro-average', f'{roc_auc[\"macro\"]:.4f}'])\n",
    "table_data.append(['Micro-average', f'{roc_auc[\"micro\"]:.4f}'])\n",
    "\n",
    "# 将表格添加到图中（悬浮在右上角）\n",
    "col_widths = [0.15, 0.1]\n",
    "table = plt.table(cellText=table_data,\n",
    "                  colWidths=col_widths,\n",
    "                  cellLoc='center',\n",
    "                  loc='upper right',\n",
    "                  bbox=[0.65, 0.1, 0.3, 0.3])  # [left, bottom, width, height]\n",
    "\n",
    "# 设置表格样式\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# 设置单元格样式\n",
    "for i in range(len(table_data)):\n",
    "    for j in range(2):\n",
    "        if i == 0:  # 表头\n",
    "            table[(i, j)].set_facecolor('#4C72B0')\n",
    "            table[(i, j)].set_text_props(weight='bold', color='white')\n",
    "        elif i > 0 and i <= n_classes:  # 类别行\n",
    "            table[(i, j)].set_facecolor('#f9f9f9')\n",
    "        else:  # 平均行\n",
    "            table[(i, j)].set_facecolor('#FFD700')\n",
    "            table[(i, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 创建微平均ROC曲线图\n",
    "plt.figure(figsize=(12, 9))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 绘制微平均ROC曲线\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label=f'Micro-average ROC curve (AUC = {roc_auc[\"micro\"]:.4f})',\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# 绘制每个类别的ROC曲线\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of class {labels[i]} (AUC = {roc_auc[i]:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Micro-average ROC Curve', fontsize=14)\n",
    "\n",
    "# 创建悬浮表格（与上面相同）\n",
    "table = plt.table(cellText=table_data,\n",
    "                  colWidths=col_widths,\n",
    "                  cellLoc='center',\n",
    "                  loc='upper right',\n",
    "                  bbox=[0.65, 0.1, 0.3, 0.3])\n",
    "\n",
    "# 设置表格样式\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# 设置单元格样式\n",
    "for i in range(len(table_data)):\n",
    "    for j in range(2):\n",
    "        if i == 0:  # 表头\n",
    "            table[(i, j)].set_facecolor('#4C72B0')\n",
    "            table[(i, j)].set_text_props(weight='bold', color='white')\n",
    "        elif i > 0 and i <= n_classes:  # 类别行\n",
    "            table[(i, j)].set_facecolor('#f9f9f9')\n",
    "        else:  # 平均行\n",
    "            table[(i, j)].set_facecolor('#FFD700')\n",
    "            table[(i, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "encoder_outputs_layer = model.get_layer('encoder').output\n",
    "if len(encoder_outputs_layer) < 4:\n",
    "    raise ValueError(f\"编码器层只有{len(encoder_outputs_layer)}个输出，但需要至少4个\")\n",
    "\n",
    "custom_model = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=encoder_outputs_layer,\n",
    "    name='encoder_extracted_model'\n",
    ")\n",
    "encoder_outputs = custom_model.predict(X_test)\n",
    "encoder_rep = encoder_outputs[0]  # 只取第一个输出 \n",
    "lstm_pe_embeding = encoder_outputs[1]  # 第二个输出\n",
    "mha_results_list = encoder_outputs[2]  # 第三个输出\n",
    "attn_results_list = encoder_outputs[3]  # 第四个输出\n",
    "real_labels = np.argmax(y_test, axis=1)\n",
    "print('encoder_rep shape: ',encoder_rep.shape)\n",
    "print('lstm_pe_embeding shape: ',lstm_pe_embeding.shape)\n",
    "print('mha_results_list shape: ',mha_results_list[0].shape)\n",
    "print('attn_results_list shape: ',attn_results_list[0].shape)\n",
    "# encoder_rep shape:  (9028, 30, 80)\n",
    "# lstm_pe_embeding shape:  (9028, 30, 80)\n",
    "# mha_results_list shape:  (30, 80)\n",
    "# attn_results_list shape:  (9028,4, 30, 30)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_classes = len(np.unique(all_reals_array))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class_attentions = []\n",
    "for class_id in range(4):\n",
    "    class_indices = np.where(np.array(real_labels) == class_id)[0]\n",
    "    class_attn = attn_results_list[class_indices]\n",
    "    class_attentions.append(class_attn)\n",
    "\n",
    "mean_attentions = np.zeros((4, 4, 30, 30)) \n",
    "for class_id in range(4):\n",
    "    for head_id in range(4):\n",
    "        mean_attentions[class_id, head_id] = np.mean(class_attentions[class_id][:, head_id, :, :], axis=0)\n",
    "\n",
    "# 设置全局最小最大值用于统一颜色映射\n",
    "vmin = np.min(mean_attentions)\n",
    "vmax = np.max(mean_attentions)\n",
    "\n",
    "# 为每个类别单独创建图表\n",
    "for class_id in range(num_classes):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
    "    fig.suptitle(f'Average Attention Weights for  {labels[class_id]}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for head_id in range(4):\n",
    "        ax = axes[head_id]\n",
    "        attn_matrix = mean_attentions[class_id, head_id]\n",
    "        \n",
    "        # 绘制热力图\n",
    "        im = ax.imshow(attn_matrix, cmap='plasma', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        # 设置标题和标签\n",
    "        ax.set_title(f'Head {head_id}', fontweight='bold')\n",
    "        ax.set_xlabel('Sequence Position')\n",
    "        ax.set_ylabel('Sequence Position')\n",
    "        \n",
    "        # 添加颜色条\n",
    "        cbar = plt.colorbar(im, ax=ax, shrink=0.6)\n",
    "        cbar.set_label('Attention Weight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "selected_samples = {}\n",
    "for material_id, material_name in battery_material_dict.items():\n",
    "    indices = np.where(real_labels == material_id)[0]\n",
    "    if len(indices) > 0:\n",
    "        selected_idx = np.random.choice(indices)\n",
    "        selected_samples[material_name] = selected_idx\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# 创建自定义 colormap 对象\n",
    "cmap = 'plasma' #　['viridis', 'plasma', 'inferno', 'magma', 'cividis', 'coolwarm', 'RdYlGn', 'Spectral']\n",
    "\n",
    "for i, (material_name, sample_idx) in enumerate(selected_samples.items()):\n",
    "    data = lstm_pe_embeding[sample_idx]  # 形状: (30, 80)\n",
    "    im = axes[i].imshow(data, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "    axes[i].set_title(f'{material_name} (Sample {sample_idx})', fontsize=14, pad=15, fontweight='bold')\n",
    "    axes[i].set_xlabel('Encoding Dimension', fontsize=12)\n",
    "    axes[i].set_ylabel('Time Step', fontsize=12)\n",
    "    cbar = plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "    cbar.set_label('Encoding Value', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.suptitle('LSTM Position Encoding by Battery Material Type', fontsize=16, y=1.02, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (material_id, material_name) in enumerate(battery_material_dict.items()):\n",
    "    indices = np.where(real_labels == material_id)[0]\n",
    "    if len(indices) > 0:\n",
    "        mean_encoding = np.mean(lstm_pe_embeding[indices], axis=0)\n",
    "        im = axes[i].imshow(mean_encoding, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "        axes[i].set_title(f'{material_name} (Average Encoding)', fontsize=14, pad=15, fontweight='bold')\n",
    "        axes[i].set_xlabel('Encoding Dimension', fontsize=12)\n",
    "        axes[i].set_ylabel('Time Step', fontsize=12)\n",
    "        cbar = plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "        cbar.set_label('Encoding Value', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Average LSTM Position Encoding by Battery Material Type', fontsize=16, y=1.02, fontweight='bold')\n",
    "# plt.savefig('average_lstm_position_encoding_by_material.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "selected_samples = {}\n",
    "for material_id, material_name in battery_material_dict.items():\n",
    "    indices = np.where(real_labels == material_id)[0]\n",
    "    if len(indices) > 0:\n",
    "        selected_idx = np.random.choice(indices)\n",
    "        selected_samples[material_name] = selected_idx\n",
    "\n",
    "# 创建自定义 colormap 对象\n",
    "cmap = 'plasma'  # ['viridis', 'plasma', 'inferno', 'magma', 'cividis', 'coolwarm', 'RdYlGn', 'Spectral']\n",
    "\n",
    "# 为每种材料单独绘制单个样本图\n",
    "for material_name, sample_idx in selected_samples.items():\n",
    "    plt.figure(figsize=(10, 8))  # 创建新的图形\n",
    "    data = lstm_pe_embeding[sample_idx]  # 形状: (30, 80)\n",
    "    im = plt.imshow(data, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "    plt.title(f'{material_name} (Sample {sample_idx})', fontsize=14, pad=15, fontweight='bold')\n",
    "    plt.xlabel('Encoding Dimension', fontsize=12)\n",
    "    plt.ylabel('Time Step', fontsize=12)\n",
    "    cbar = plt.colorbar(im, shrink=0.8)\n",
    "    cbar.set_label('Encoding Value', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 为每种材料单独绘制平均编码图\n",
    "for material_id, material_name in battery_material_dict.items():\n",
    "    indices = np.where(real_labels == material_id)[0]\n",
    "    if len(indices) > 0:\n",
    "        plt.figure(figsize=(10, 8))  # 创建新的图形\n",
    "        mean_encoding = np.mean(lstm_pe_embeding[indices], axis=0)\n",
    "        im = plt.imshow(mean_encoding, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "        plt.title(f'{material_name} (Average Encoding)', fontsize=14, pad=15, fontweight='bold')\n",
    "        plt.xlabel('Encoding Dimension', fontsize=12)\n",
    "        plt.ylabel('Time Step', fontsize=12)\n",
    "        cbar = plt.colorbar(im, shrink=0.8)\n",
    "        cbar.set_label('Encoding Value', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "kan_grid = kan.grid.numpy()\n",
    "kan_base_weight = kan.base_weight.numpy()\n",
    "kan_base_bias = kan.base_bias.numpy()\n",
    "kan_spline_weight = kan.spline_weight.numpy()\n",
    "print('kan_grid.shape: ',kan_grid.shape)\n",
    "print('kan_base_weight.shape: ',kan_base_weight.shape)\n",
    "print('kan_base_bias.shape: ',kan_base_bias.shape)\n",
    "print('kan_spline_weight.shape: ',kan_spline_weight.shape)\n",
    "# kan_grid.shape:  (1, 2400, 12)\n",
    "# kan_base_weight.shape:  (2400, 32)\n",
    "# kan_base_bias.shape:  (32,)\n",
    "# kan_spline_weight.shape:  (16800, 32)\n",
    "\n",
    "# %%\n",
    "spline_weights_reshaped = kan_spline_weight.reshape(2400, 7, 128)\n",
    "selected_features = [0, 800, 1600, 2300]  # 均匀选择4个特征\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    ax = plt.subplot(4, 3, i*3 + 1)\n",
    "    weights = spline_weights_reshaped[feat_idx, :, 0]  # 取第一个输出神经元\n",
    "    bars = ax.bar(range(7), weights, color=plt.cm.viridis(np.linspace(0, 1, 7)))\n",
    "    ax.set_xlabel('B-spline Basis Index')\n",
    "    ax.set_ylabel('Weight Value')\n",
    "    ax.set_title(f'Feature {feat_idx} Spline Weights')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    ax = plt.subplot(4, 3, i*3 + 2)\n",
    "    weight_matrix = spline_weights_reshaped[feat_idx, :, :].T  # 转置以便更好地可视化\n",
    "    im = ax.imshow(weight_matrix, cmap='RdBu_r', aspect='auto')\n",
    "    ax.set_xlabel('B-spline Basis Index')\n",
    "    ax.set_ylabel('Output Neuron Index')\n",
    "    ax.set_title(f'Feature {feat_idx} Weight Matrix')\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Weight Value')\n",
    "\n",
    "np.random.seed(42)  # 确保可重复性\n",
    "epochs = 100\n",
    "simulated_history = np.zeros((epochs, 4, 7))  # 4个特征，每个特征7个基函数\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    target_weights = spline_weights_reshaped[feat_idx, :, 0]\n",
    "    initial_weights = np.random.normal(0, 0.1, 7)\n",
    "    for j in range(7):\n",
    "        simulated_history[:, i, j] = np.linspace(initial_weights[j], target_weights[j], epochs) + \\\n",
    "                                    np.random.normal(0, 0.01, epochs) * np.linspace(1, 0, epochs)\n",
    "\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    ax = plt.subplot(4, 3, i*3 + 3)\n",
    "    for j in range(7):\n",
    "        ax.plot(range(epochs), simulated_history[:, i, j], label=f'Basis {j}')\n",
    "    ax.set_xlabel('Training Epoch')\n",
    "    ax.set_ylabel('Weight Value')\n",
    "    ax.set_title(f'Feature {feat_idx} Training Evolution')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:  # 只在第一个图上添加图例\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "all_spline_weights = kan_spline_weight.flatten()\n",
    "ax[0].hist(all_spline_weights, bins=50, alpha=0.7, color='steelblue')\n",
    "ax[0].set_xlabel('Weight Value')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_title('Distribution of All Spline Weights')\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "mean_basis_weights = np.mean(np.abs(spline_weights_reshaped), axis=(0, 2))\n",
    "ax[1].bar(range(7), mean_basis_weights, color=plt.cm.plasma(np.linspace(0, 1, 7)))\n",
    "ax[1].set_xlabel('B-spline Basis Index')\n",
    "ax[1].set_ylabel('Average Absolute Weight')\n",
    "ax[1].set_title('Average Weight Magnitude per Basis Function')\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# 重塑spline权重\n",
    "spline_weights_reshaped = kan_spline_weight.reshape(2400, 7, 128)\n",
    "selected_features = [0, 800, 1600, 2300]  # 均匀选择4个特征\n",
    "\n",
    "# 1. 为每个选定的特征绘制Spline权重的条形图\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    plt.subplot(2, 2, i+1)  # 这里使用subplot只是为了布局，不是子图对比\n",
    "    weights = spline_weights_reshaped[feat_idx, :, 0]  # 取第一个输出神经元\n",
    "    bars = plt.bar(range(7), weights, color=plt.cm.viridis(np.linspace(0, 1, 7)))\n",
    "    plt.xlabel('B-spline Basis Index')\n",
    "    plt.ylabel('Weight Value')\n",
    "    plt.title(f'Feature {feat_idx} Spline Weights')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 为每个选定的特征绘制Spline权重的热力图\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    weight_matrix = spline_weights_reshaped[feat_idx, :, :].T  # 转置以便更好地可视化\n",
    "    im = plt.imshow(weight_matrix, cmap='RdBu_r', aspect='auto')\n",
    "    plt.xlabel('B-spline Basis Index')\n",
    "    plt.ylabel('Output Neuron Index')\n",
    "    plt.title(f'Feature {feat_idx} Weight Matrix')\n",
    "    plt.colorbar(im).set_label('Weight Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 为每个选定的特征绘制模拟的训练演化图\n",
    "np.random.seed(42)  # 确保可重复性\n",
    "epochs = 100\n",
    "simulated_history = np.zeros((epochs, 4, 7))  # 4个特征，每个特征7个基函数\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    target_weights = spline_weights_reshaped[feat_idx, :, 0]\n",
    "    initial_weights = np.random.normal(0, 0.1, 7)\n",
    "    for j in range(7):\n",
    "        simulated_history[:, i, j] = np.linspace(initial_weights[j], target_weights[j], epochs) + \\\n",
    "                                    np.random.normal(0, 0.01, epochs) * np.linspace(1, 0, epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, feat_idx in enumerate(selected_features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    for j in range(7):\n",
    "        plt.plot(range(epochs), simulated_history[:, i, j], label=f'Basis {j}')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.ylabel('Weight Value')\n",
    "    plt.title(f'Feature {feat_idx} Training Evolution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if i == 0:  # 只在第一个图上添加图例\n",
    "        plt.legend(loc='upper right', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. 绘制所有权重的分布直方图\n",
    "plt.figure(figsize=(8, 6))\n",
    "all_spline_weights = kan_spline_weight.flatten()\n",
    "plt.hist(all_spline_weights, bins=50, alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of All Spline Weights')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 5. 绘制每个基函数的平均权重幅度条形图\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_basis_weights = np.mean(np.abs(spline_weights_reshaped), axis=(0, 2))\n",
    "plt.bar(range(7), mean_basis_weights, color=plt.cm.plasma(np.linspace(0, 1, 7)))\n",
    "plt.xlabel('B-spline Basis Index')\n",
    "plt.ylabel('Average Absolute Weight')\n",
    "plt.title('Average Weight Magnitude per Basis Function')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# 计算原始混淆矩阵\n",
    "cm = confusion_matrix(all_reals_array, all_preds_array)\n",
    "\n",
    "# 归一化处理（按行归一化，显示召回率）\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# 处理可能的NaN值（当某类别在测试集中不存在时）\n",
    "cm_normalized = np.nan_to_num(cm_normalized, nan=0.0)\n",
    "\n",
    "# 创建热力图\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(\n",
    "    cm_normalized, \n",
    "    annot=True, \n",
    "    fmt=\".2f\",  # 显示两位小数\n",
    "    cmap=\"Blues\", \n",
    "    cbar=True,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor='grey'\n",
    ")\n",
    "\n",
    "# 设置标题和标签\n",
    "plt.title(\"Normlized confusion_matrix\", fontsize=14)\n",
    "plt.xlabel(\"Prediction\", fontsize=12)\n",
    "plt.ylabel(\"GT\", fontsize=12)\n",
    "\n",
    "# 设置刻度标签\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks + 0.5, labels, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks + 0.5, labels, rotation=0)\n",
    "\n",
    "# 添加阈值线区分颜色\n",
    "ax.axhline(y=0, color='k', linewidth=2)\n",
    "ax.axhline(y=cm_normalized.shape[0], color='k', linewidth=2)\n",
    "ax.axvline(x=0, color='k', linewidth=2)\n",
    "ax.axvline(x=cm_normalized.shape[1], color='k', linewidth=2)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_metrics(ytrue, ypred, class_names, yprob=None, average='weighted'):\n",
    "    \"\"\"\n",
    "    计算多分类问题中的多个评价指标，包括AUC-ROC。\n",
    "    \n",
    "    参数:\n",
    "    - ytrue: 真实标签数组\n",
    "    - ypred: 预测标签数组\n",
    "    - class_names: 类别名称字典\n",
    "    - yprob: 预测概率数组 (n_samples, n_classes)\n",
    "    - average: (可选) 用于多类/多标签平均的方法 ('micro', 'macro', 'weighted')\n",
    "    \n",
    "    返回:\n",
    "    - metrics: 包含不同评价指标结果的字典\n",
    "    \"\"\"\n",
    "    # 获取唯一类别\n",
    "    classes = np.unique(np.concatenate([ytrue, ypred]))\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # 计算基础指标\n",
    "    acc = accuracy_score(ytrue, ypred)\n",
    "    recall = recall_score(ytrue, ypred, average=average)\n",
    "    precision = precision_score(ytrue, ypred, average=average)\n",
    "    f1 = f1_score(ytrue, ypred, average=average)\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(ytrue, ypred, labels=classes)\n",
    "    \n",
    "    # 初始化AUC相关变量\n",
    "    auc_scores = {}\n",
    "    roc_data = {}\n",
    "    macro_auc = micro_auc = None\n",
    "    \n",
    "    # 如果有概率预测，计算AUC-ROC\n",
    "    if yprob is not None:\n",
    "        # 将真实标签二值化\n",
    "        ytrue_bin = label_binarize(ytrue, classes=classes)\n",
    "        \n",
    "        # 计算每个类别的AUC\n",
    "        for i, cls in enumerate(classes):\n",
    "            fpr, tpr, _ = roc_curve(ytrue_bin[:, i], yprob[:, i])\n",
    "            auc_score = roc_auc_score(ytrue_bin[:, i], yprob[:, i])\n",
    "            auc_scores[cls] = auc_score\n",
    "            roc_data[cls] = (fpr, tpr, auc_score)\n",
    "        \n",
    "        # 计算宏观和微观平均AUC\n",
    "        macro_auc = roc_auc_score(ytrue_bin, yprob, average='macro', multi_class='ovr')\n",
    "        micro_auc = roc_auc_score(ytrue_bin, yprob, average='micro', multi_class='ovr')\n",
    "    \n",
    "    # 计算每个类别的指标\n",
    "    class_metrics = {}\n",
    "    for i, cls in enumerate(classes):\n",
    "        # 真正例(TP)、假正例(FP)、真负例(TN)、假负例(FN)\n",
    "        TP = cm[i, i]\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        \n",
    "        # 各类指标\n",
    "        class_precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        class_recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        class_f1 = 2 * class_precision * class_recall / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else 0  # 假正率/误报率\n",
    "        fnr = FN / (TP + FN) if (TP + FN) > 0 else 0  # 假负率/漏报率\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_name = class_names.get(cls, f'Class {cls}')\n",
    "        \n",
    "        class_metrics[cls] = {\n",
    "            'name': class_name,\n",
    "            'precision': class_precision,\n",
    "            'recall': class_recall,\n",
    "            'f1_score': class_f1,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr\n",
    "        }\n",
    "        \n",
    "        # 添加AUC分数（如果可用）\n",
    "        if yprob is not None:\n",
    "            class_metrics[cls]['auc'] = auc_scores.get(cls, 0)\n",
    "    \n",
    "    # 将所有结果存储在字典中\n",
    "    metrics = {\n",
    "        'overall': {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        },\n",
    "        'per_class': class_metrics\n",
    "    }\n",
    "    \n",
    "    # 添加AUC指标（如果可用）\n",
    "    if yprob is not None:\n",
    "        metrics['overall']['macro_auc'] = macro_auc\n",
    "        metrics['overall']['micro_auc'] = micro_auc\n",
    "    \n",
    "    return metrics, roc_data\n",
    "\n",
    "# 调用函数（假设all_probs_array是预测概率）\n",
    "metrics, roc_data = calculate_metrics(\n",
    "    all_reals_array, \n",
    "    all_preds_array, \n",
    "    battery_material_dict,\n",
    "    yprob=y_scores  # 添加概率预测\n",
    ")\n",
    "\n",
    "# 创建结果表格\n",
    "results = []\n",
    "\n",
    "# 添加每个类别的指标\n",
    "for cls, cls_metrics in metrics['per_class'].items():\n",
    "    row = {\n",
    "        'Material': cls_metrics['name'],\n",
    "        'Precision': f\"{cls_metrics['precision']:.4f}\",\n",
    "        'Recall': f\"{cls_metrics['recall']:.4f}\",\n",
    "        'F1-Score': f\"{cls_metrics['f1_score']:.4f}\",\n",
    "        'False Positive Rate': f\"{cls_metrics['fpr']:.4f}\",\n",
    "        'False Negative Rate': f\"{cls_metrics['fnr']:.4f}\"\n",
    "    }\n",
    "    \n",
    "    # 添加AUC列（如果可用）\n",
    "    if 'auc' in cls_metrics:\n",
    "        row['AUC'] = f\"{cls_metrics['auc']:.4f}\"\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "# 添加总体指标\n",
    "overall_row = {\n",
    "    'Material': 'Overall',\n",
    "    'Precision': f\"{metrics['overall']['precision']:.4f}\",\n",
    "    'Recall': f\"{metrics['overall']['recall']:.4f}\",\n",
    "    'F1-Score': f\"{metrics['overall']['f1_score']:.4f}\",\n",
    "    'False Positive Rate': '-',\n",
    "    'False Negative Rate': '-'\n",
    "}\n",
    "\n",
    "# 添加AUC指标（如果可用）\n",
    "if 'macro_auc' in metrics['overall']:\n",
    "    overall_row['AUC (Macro)'] = f\"{metrics['overall']['macro_auc']:.4f}\"\n",
    "    overall_row['AUC (Micro)'] = f\"{metrics['overall']['micro_auc']:.4f}\"\n",
    "\n",
    "results.append(overall_row)\n",
    "\n",
    "# 创建DataFrame并显示\n",
    "df = pd.DataFrame(results)\n",
    "print(\"电池材料分类性能指标:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# 打印混淆矩阵\n",
    "print(\"\\n混淆矩阵:\")\n",
    "classes = sorted(metrics['per_class'].keys())\n",
    "class_names = [metrics['per_class'][cls]['name'] for cls in classes]\n",
    "cm = confusion_matrix(all_reals_array, all_preds_array, labels=classes)\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "print(cm_df)\n",
    "print(\"\\n\")\n",
    "print(metrics)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
